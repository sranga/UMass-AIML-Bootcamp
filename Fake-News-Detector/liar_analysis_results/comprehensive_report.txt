================================================================================
FAKE NEWS DETECTION - COMPREHENSIVE ML PIPELINE REPORT
================================================================================

1. AUTOMATED MODEL TESTING RESULTS
----------------------------------------
Best performing model: Logistic_Regression
Best F1 Score: 0.5940

Top 3 Models by F1 Score:
                     f1_macro  accuracy   cv_mean
Logistic_Regression  0.594015  0.610395  0.587912
SVM                  0.591865  0.614302  0.587734
Naive_Bayes          0.590174  0.608832  0.589690

2. LOSS FUNCTION TESTING RESULTS
----------------------------------------

3. HYPERPARAMETER TUNING RESULTS
----------------------------------------
Random_Forest:
  Best CV Score: 0.5805
  Test F1 Score: 0.5925
  Best Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 200}

Gradient_Boosting:
  Best CV Score: 0.5613
  Test F1 Score: 0.5862
  Best Parameters: {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 200}

Logistic_Regression:
  Best CV Score: 0.5877
  Test F1 Score: 0.5931
  Best Parameters: {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}

SVM:
  Best CV Score: 0.5877
  Test F1 Score: 0.5919
  Best Parameters: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}

4. CROSS-VALIDATION ANALYSIS
----------------------------------------
StratifiedKFold_5:
  Random_Forest: 0.5829 (±0.0051)
  Gradient_Boosting: 0.5637 (±0.0087)
  Logistic_Regression: 0.5923 (±0.0061)
  SVM: 0.5896 (±0.0072)

StratifiedKFold_10:
  Random_Forest: 0.5856 (±0.0129)
  Gradient_Boosting: 0.5695 (±0.0173)
  Logistic_Regression: 0.5951 (±0.0126)
  SVM: 0.5932 (±0.0135)

RepeatedStratifiedKFold:
  Random_Forest: 0.5863 (±0.0098)
  Gradient_Boosting: 0.5668 (±0.0098)
  Logistic_Regression: 0.5929 (±0.0048)
  SVM: 0.5904 (±0.0057)

StratifiedShuffleSplit:
  Random_Forest: 0.5951 (±0.0118)
  Gradient_Boosting: 0.5720 (±0.0115)
  Logistic_Regression: 0.5976 (±0.0077)
  SVM: 0.5964 (±0.0103)

5. ENSEMBLE MODEL RESULTS
----------------------------------------
Voting_Hard:
  Accuracy: 0.6163
  F1 Macro: 0.5845
  F1 Weighted: 0.5978

Voting_Soft:
  Accuracy: 0.6166
  F1 Macro: 0.5962
  F1 Weighted: 0.6067

6. GENERALIZATION AND OVERFITTING ANALYSIS
----------------------------------------
Random_Forest:
  Final Validation Score: 0.5869
  Overfitting Gap: 0.4121
  Is Overfitting: True
  Stability: 0.9910

Gradient_Boosting:
  Final Validation Score: 0.5693
  Overfitting Gap: 0.2532
  Is Overfitting: True
  Stability: 0.9949

Logistic_Regression:
  Final Validation Score: 0.5892
  Overfitting Gap: 0.1572
  Is Overfitting: True
  Stability: 0.9883

SVM:
  Final Validation Score: 0.5871
  Overfitting Gap: 0.3524
  Is Overfitting: True
  Stability: 0.9899

Ensemble:
  Final Validation Score: 0.5875
  Overfitting Gap: 0.3595
  Is Overfitting: True
  Stability: 0.9919

================================================================================
RECOMMENDATIONS:
================================================================================
1. Use Voting_Soft ensemble model for best performance
2. Most stable models: Random_Forest, Gradient_Boosting, Logistic_Regression, SVM, Ensemble
3. Consider additional feature engineering for improved performance
4. Collect more diverse training data to reduce overfitting
5. Implement online learning for real-time fake news detection
